{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b66891-d8cb-487c-84ae-4988c7097bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import json\n",
    "from llmlingua import PromptCompressor\n",
    "import faiss\n",
    "import time\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0ea49d-74d2-4881-971d-2ff1214fa691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"updated_shoes_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5c9997-6277-480a-ba09-5508d1e519f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "\n",
    "df['size'] = df['size'].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a52a38-b9b1-4487-84d7-bd20b2c754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size'] = df['size'].apply(lambda x: list(map(float, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01622864-999b-4def-8680-c2ce8e062011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    query = query.lower()  # Lowercase the query\n",
    "    tokens = word_tokenize(query)  # Tokenize the query\n",
    "    return tokens\n",
    "# Load a pre-trained spaCy model for entity recognition\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to recognize entities and map them to dataset categories\n",
    "def parse_query(query,df):\n",
    "    doc = nlp(query)\n",
    "    entities = {}\n",
    "\n",
    "    # Expanded dictionary of synonyms for occasions and genders\n",
    "    occasion_synonyms = {\n",
    "        'formal': ['formal', 'office', 'business', 'professional'],\n",
    "        'casual': ['casual', 'everyday', 'daily', 'regular', 'weekend'],\n",
    "        'ethnic': ['ethnic', 'traditional', 'cultural', 'heritage'],\n",
    "        'party': ['party', 'fancy', 'evening', 'event', 'birthday', 'celebration', 'festive'],\n",
    "        'riding': ['riding', 'biking', 'motorcycle', 'cycling'],\n",
    "        'sports': ['sports', 'athletic', 'gym', 'training', 'running', 'soccer', 'football', 'basketball', 'tennis', 'hiking', 'fitness'],\n",
    "        'wedding': ['wedding', 'bride', 'groom', 'marriage', 'nuptial'],\n",
    "        'work': ['work', 'standing', 'office', 'workplace', 'job'],\n",
    "        'summer': ['summer', 'sandals', 'beach', 'vacation'],\n",
    "        'winter': ['winter', 'cold', 'snow', 'boots'],\n",
    "    }\n",
    "\n",
    "    gender_synonyms = {\n",
    "        'male': [\n",
    "            'male', 'men', 'man', 'boy', 'son', 'gentleman',\n",
    "            'guy', 'lad', 'brother', 'father', 'husband',\n",
    "            'he', 'him', 'his', 'masculine', 'dude',\n",
    "            'mr', 'sir', 'uncle', 'nephew', 'grandfather',\n",
    "            'dad', 'papa', 'pa', 'fella'\n",
    "        ],\n",
    "        'female': [\n",
    "            'female', 'women', 'woman', 'girl', 'wife', 'daughter',\n",
    "            'lady', 'miss', 'mrs', 'ms', 'sister',\n",
    "            'mother', 'aunt', 'niece', 'grandmother',\n",
    "            'she', 'her', 'hers', 'feminine', 'madam',\n",
    "            'ma\\'am', 'gal', 'mom', 'mama', 'mum',\n",
    "            'mummy', 'mommy', 'granny', 'lass', 'queen',\n",
    "            'princess', 'dame'\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    description_keywords = {\n",
    "        'comfortable': ['comfortable', 'cozy', 'snug', 'comfy', 'relaxed'],\n",
    "        'stylish': ['stylish', 'fashionable', 'trendy', 'chic', 'elegant'],\n",
    "        'durable': ['durable', 'long-lasting', 'sturdy', 'tough', 'hardy'],\n",
    "        'lightweight': ['lightweight', 'light', 'easy', 'flexible'],\n",
    "        'unique': ['unique', 'special', 'different', 'distinctive'],\n",
    "        'support': ['support', 'good support', 'arch support', 'cushioning'],\n",
    "        'sparkle': ['sparkle', 'glitter', 'shiny', 'dazzling'],\n",
    "    }\n",
    "\n",
    "    # Extracting entities from the query\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"MONEY\":\n",
    "            price_match = re.search(r'\\d+', ent.text)\n",
    "            if price_match:\n",
    "                entities['price'] = int(price_match.group())\n",
    "        elif ent.label_ == \"CARDINAL\":\n",
    "          if ent.text.isdigit():\n",
    "            number = int(ent.text)\n",
    "            if 1 <= number <= 15:  # Common shoe sizes range\n",
    "                entities.setdefault('size', []).append(float(number))\n",
    "    brands=[]\n",
    "    tokens = preprocess_query(query)\n",
    "    unique_brands = df['brand'].unique()\n",
    "    unique_brands = [brand.lower() for brand in unique_brands]\n",
    "    for token in tokens:\n",
    "        if token in unique_brands:\n",
    "            brands.append(token)\n",
    "    if brands:\n",
    "        entities['brand']=brands\n",
    "    # Directly check the query for gender-related terms\n",
    "    for gender, keywords in gender_synonyms.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(rf'\\b{keyword}\\b', query, re.IGNORECASE):\n",
    "                entities['gender'] = gender\n",
    "\n",
    "    # Enhanced handling of occasions\n",
    "    for occasion, keywords in occasion_synonyms.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(rf'\\b{keyword}\\b', query, re.IGNORECASE):\n",
    "                entities['occasion'] = occasion\n",
    "\n",
    "    # Enhanced handling of descriptions\n",
    "    matched_descriptions = []\n",
    "    for description, keywords in description_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(rf'\\b{keyword}\\b', query, re.IGNORECASE):\n",
    "                matched_descriptions.append(description)\n",
    "    if matched_descriptions:\n",
    "        entities['description'] = ' '.join(matched_descriptions)\n",
    "\n",
    "    # Handling price ranges\n",
    "    price_range_match = re.search(r'price (range )?between (\\d+) (and|to) (\\d+)', query, re.IGNORECASE)\n",
    "    if price_range_match:\n",
    "        entities['price_range'] = (int(price_range_match.group(2)), int(price_range_match.group(4)))\n",
    "\n",
    "    price_limit_match = re.search(r'under (\\d+)', query, re.IGNORECASE)\n",
    "    if price_limit_match:\n",
    "        entities['cprice'] = int(price_limit_match.group(1))\n",
    "\n",
    "    # Handling discount or offer\n",
    "    offer_match = re.search(r'(\\d+)% (off|discount)', query, re.IGNORECASE)\n",
    "    if offer_match:\n",
    "        entities['offer'] = float(offer_match.group(1))\n",
    "\n",
    "    # Handling ratings\n",
    "    rating_match = re.search(r'rating (above|greater than|over) (\\d+(\\.\\d+)?)', query, re.IGNORECASE)\n",
    "    if rating_match:\n",
    "        entities['rating_threshold'] = float(rating_match.group(2))\n",
    "\n",
    "    # Handling top rated requests\n",
    "    if \"top rated\" in query.lower():\n",
    "        entities['rating'] = 5\n",
    "\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6266699c-0493-4888-9872-7340389b0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_shoes(shoes_data, parsed_query):\n",
    "    # Filter based on gender\n",
    "    if 'gender' in parsed_query:\n",
    "        shoes_data = shoes_data[shoes_data['gender'].str.lower() == parsed_query['gender'].lower()]\n",
    "    # Filter based on price range\n",
    "\n",
    "    # Filter based on brand\n",
    "    if 'brand' in parsed_query:\n",
    "        shoes_data = shoes_data[shoes_data['brand'].str.lower().isin(parsed_query[\"brand\"])]\n",
    "\n",
    "    # Filter based on occasion\n",
    "    if 'occasion' in parsed_query:\n",
    "        shoes_data = shoes_data[shoes_data['ocassion'].str.lower() == parsed_query['occasion'].lower()]\n",
    "        \n",
    "    # Filter based on minimum rating\n",
    "    if 'min_rating' in parsed_query:\n",
    "        shoes_data = shoes_data[shoes_data['rating'] >= parsed_query['min_rating']]\n",
    "    \n",
    "    if 'price_range' in parsed_query:\n",
    "        min_price, max_price = parsed_query['price_range']\n",
    "        shoes_data = shoes_data[(shoes_data['cprice'] >= min_price) & (shoes_data['cprice'] <= max_price)]\n",
    "    # Filter based on size\n",
    "    if 'size' in parsed_query:\n",
    "        desired_size = parsed_query['size'][0]\n",
    "        shoes_data = shoes_data[shoes_data['size'].apply(lambda sizes: desired_size in sizes)]\n",
    "\n",
    "    return shoes_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "619e19b0-fe8f-4b10-b978-0318ec50838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the MiniLM tokenizer and model\n",
    "model_name = 'sentence-transformers/all-MiniLM-l12-v2'\n",
    "#model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a25bfeb-5795-4edb-aa07-e0dcd5f96e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378b07ab-4577-4001-acac-215ec07a481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch embeddings shape: (46879, 384) total time taken: 47.75185942649841\n"
     ]
    }
   ],
   "source": [
    "def generate_batch_embeddings(text_list, batch_size=32):\n",
    "    embeddings_list = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        \n",
    "        embeddings_list.append(embeddings.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(embeddings_list, axis=0)\n",
    "\n",
    "# Example: Embeddings for a list of sentences\n",
    "text_list = df[\"descrption\"].tolist()\n",
    "s=time.time()\n",
    "embeddings = generate_batch_embeddings(text_list)\n",
    "l=time.time()\n",
    "print(\"Batch embeddings shape:\", embeddings.shape,\"total time taken:\",l-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8805eea5-7fed-4276-a583-598097cbd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df=pd.DataFrame(embeddings.tolist())\n",
    "#filterd_embedding_df=embedding_df.iloc[filtered_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438627bc-d657-4783-b602-8b503c04f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_embedding(text):\n",
    "    # Tokenize and move the inputs to GPU\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        outputs = model(**inputs)\n",
    "        # Perform mean pooling\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return embeddings.cpu().numpy()  # Move embeddings back to CPU for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9025686-fe95-481d-a0fb-53d1668d76cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silirity_search(embeddings_df,query):\n",
    "    embedding=embeddings_df.to_numpy()\n",
    "    d = embedding.shape[1]\n",
    "    res = faiss.StandardGpuResources()  # Use a single GPU\n",
    "    index = faiss.IndexFlatL2(d)  # L2 distance\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index)  # Move index to GPU\n",
    "    gpu_index.add(embedding)\n",
    "    query_embedding = generate_text_embedding(query)\n",
    "    k = 10  # Number of nearest neighbors to retrieve\n",
    "    distances, indices = gpu_index.search(np.array([query_embedding.flatten()]), k)\n",
    "    return distances, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "474f7e5e-c8b6-4fa5-a348-62af139567fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_results(result_df, rating_weight=0.6, review_weight=0.4, top_k=5):\n",
    "    boosted_results = []\n",
    "\n",
    "    for i in range(len(result_df)):\n",
    "        similarity_score = 1 / (1 + result_df[\"distance\"].iloc[i])  # Convert distance to similarity\n",
    "        rating_score = result_df['rating'].iloc[i] / 5.0  # Assuming rating is out of 5\n",
    "        review_score = np.log1p(result_df['reviews'].iloc[i]) / np.log1p(1000)  # Normalize based on an assumed max of 1000 reviews\n",
    "        boosted_score = similarity_score + (rating_weight * rating_score) + (review_weight * review_score)\n",
    "        boosted_results.append(boosted_score)\n",
    "    result_df[\"boosted_score\"]=boosted_results\n",
    "    #sorting from higher to lower\n",
    "    result_df = result_df.sort_values(by='boosted_score', ascending=False)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99f8c652-beff-4df7-b06e-3c76441b40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_lingua = PromptCompressor(\n",
    "    model_name=\"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\",\n",
    "    model_config={\"revision\": \"main\"},\n",
    "    use_llmlingua2=True,\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "\n",
    "# Function definition\n",
    "def compress_query_prompt(query):\n",
    "    demonstration_str = query['demonstration_str']\n",
    "    instruction = query['instruction']\n",
    "    question = query['question']\n",
    "    # 6x Compression\n",
    "    compressed_prompt = llm_lingua.compress_prompt(\n",
    "        demonstration_str.split(\"\\n\"),\n",
    "        instruction=instruction,\n",
    "        question=question,\n",
    "        target_token=300,\n",
    "        rank_method=\"longllmlingua\",\n",
    "        context_budget=\"+100\",\n",
    "        dynamic_context_compression_ratio=0.4,\n",
    "        reorder_context=\"sort\",\n",
    "    )\n",
    "\n",
    "    return json.dumps(compressed_prompt, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b0dfb9-d772-44e2-916f-68a5ee8eb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"GEMINI-API-KEY\")\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 200,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model_gen = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "  system_instruction=\"your  a shoe recommendation system you will answer user query using search results\",\n",
    ")\n",
    "\n",
    "def handle_user_query(query,compressed_prompt):\n",
    "    prompt=f\"You are an shoe recommendation system. Answer this user query: '{query}' with the following context:\\n{compressed_prompt}\"\n",
    "    response = model_gen.generate_content(prompt)\n",
    "    return(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4111d048-ff2d-4055-a395-67f6556ddebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache from 'C:\\Users\\Suresh.K\\gradio_cached_examples\\15' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
      "\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pipeline(message, history):\n",
    "    query= message\n",
    "    #query parser seperating entites from query\n",
    "    value=parse_query(query,df)\n",
    "    #filter data using entites\n",
    "    filtered_data=filter_shoes(df,value)\n",
    "    #storing embedded data into pandas dataframe\n",
    "    embedding_df=pd.DataFrame(embeddings.tolist())\n",
    "    #extracting filter data index from embbeddings\n",
    "    filterd_embedding_df=embedding_df.iloc[filtered_data.index]\n",
    "    #similarty search\n",
    "    distance,indices=silirity_search(filterd_embedding_df,query)\n",
    "    result_df=filtered_data.iloc[indices[0]]\n",
    "    result_df['distance']=distance.flatten().tolist()\n",
    "    #adding boosted values\n",
    "    result=boost_results(result_df.head())\n",
    "    result=result.drop([\"combined_description\",\"UID\",\"distance\",\"boosted_score\"],axis=1)\n",
    "    query_info = {\n",
    "     'demonstration_str': result.to_string(),  # Results from information retrieval process\n",
    "     'instruction': \"Write a high-quality answer for the given question using only the provided search results.\",\n",
    "     'question': query \n",
    "    }\n",
    "    #prompt engineering and prompt compression\n",
    "    res = compress_query_prompt(query_info)\n",
    "    data = json.loads(res)\n",
    "    compressed_prompt = data[\"compressed_prompt\"]\n",
    "    #using gemini for generative model\n",
    "    ans=handle_user_query(query,compressed_prompt)\n",
    "    return ans\n",
    "\n",
    "gr.ChatInterface(\n",
    "    pipeline,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Type here..\", container=False, scale=7),\n",
    "    title=\"shoe recommendation system\",\n",
    "    description=\"Please specify your requirement like gender,ocassion,brand,size,price and rating\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"Adidas men shoes for walking or running \"],\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e07fee-bded-4678-9077-f81e66f9fa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
